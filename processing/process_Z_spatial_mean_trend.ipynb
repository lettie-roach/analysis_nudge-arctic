{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sys\n",
    "sys.path.insert(1, '/glade/u/home/lettier/analysis/')\n",
    "import master_utils as myf\n",
    "xr.set_options(keep_attrs=True)\n",
    "from xgcm import Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to interpolate CESM1 output onto pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_xgcm(ds, var):\n",
    "    # Calculate the pressure at every time, lev, lat, lon\n",
    "    p = (ds['hyam']*ds['P0'] + ds['hybm']*ds['PS'])/100\n",
    "    # Assign it as a variable in the dataset\n",
    "    ds = ds.assign({'p': np.log(p)})\n",
    "    \n",
    "    # Create an xgcm Grid object with a Z coordinate given by 'lev'\n",
    "    grid = Grid(ds, coords={'Z': {'center': 'lev'}}, periodic=False)\n",
    "    \n",
    "    # Give the array of pressures to interpolate to\n",
    "    p_target = np.array([10., 20., 30., 50., 70., 100., 150., 200., 250.,\n",
    "                         300., 400., 500., 600., 650., 700., 750., 800., 850.,\n",
    "                         900., 950., 1000.])\n",
    "    \n",
    "    # Use the transform method to interpolate to constant pressure given the target pressures above\n",
    "    # The target_data parameter tells it what variable to use to base the transformation on. \n",
    "    # In our case, we're using the model pressure at every point calculated above\n",
    "    varout = grid.transform(ds[var], 'Z', np.log(p_target), target_data=ds.p)\n",
    "    \n",
    "    # Rename the new dimension and assign the coordinate as the target pressures above\n",
    "    varout = varout.rename({'p': 'plev'})\n",
    "    varout = varout.assign_coords({'plev': p_target})\n",
    "    \n",
    "    return varout.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvariables = ['Z3','T','PS','hybm','hyam','P0']\n",
    "mytime = pd.date_range(start=\"1979-01-01\",end=\"2018-12-31\", freq='M')\n",
    "edir = '/glade/scratch/wriggles/archive/'\n",
    "ldir = '/glade/scratch/lettier/ed_archive/'\n",
    "mydir = '/glade/work/lettier/NUDGE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_nudge (nudge_name, myvariables):\n",
    "    ds_a = xr.open_mfdataset(edir+nudge_name+'/atm/hist/*.h0.*')[myvariables]\n",
    "    ds_b = xr.open_mfdataset(edir+nudge_name+'_21C/atm/hist/*.h0.*')[myvariables]\n",
    "    ds = xr.concat([ds_a,ds_b],dim='time')\n",
    "    ds['time'] = mytime\n",
    "    ds['names'] = nudge_name\n",
    "    ds = ds.set_coords('names')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_lens (e, myvariables):\n",
    "    ledir = '/glade/collections/cdg/data/cesmLE/CESM-CAM5-BGC-LE/atm/proc/tseries/monthly/'\n",
    "\n",
    "    ens = str(e)\n",
    "    if e<10:\n",
    "        ens = '0'+str(e)\n",
    "    tmp = []\n",
    "    print(ens)\n",
    "    for var in ['Z3','PS','T']:\n",
    "        myfiles = sorted([ledir+var+'/'+f for f in os.listdir(ledir+var) if ('B20TRC5CNBDRD' in f or 'BRCP85C5CNBDRD' in f) and '0'+ens+'.cam.h0.'+var in f ])\n",
    "        myfiles = [f for f in myfiles if '.192001-199912.nc' not in f and '208101-210012.nc' not in f]\n",
    "        ds = xr.open_mfdataset(myfiles).sel(time=slice('1979-02','2019-01'))\n",
    "        ds['time'] = mytime\n",
    "        tmp.append(ds)\n",
    "        \n",
    "    ds = xr.merge(tmp)\n",
    "    ds['names'] = 'LENS'+ens\n",
    "    ds = ds.set_coords('names')\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries (inds):\n",
    "    name = str(inds.names.values)\n",
    "    \n",
    "    \n",
    "    listds = []\n",
    "    for seas in ['DJF','MAM','JJA','SON']:\n",
    "        seasds = inds.where(inds['time.season'] == seas).groupby('time.year').mean(dim='time')\n",
    "    \n",
    "        ds_a = regrid_xgcm(seasds, 'Z3').to_dataset(name='Z3')\n",
    "        ds_b = regrid_xgcm(seasds, 'T').to_dataset(name='T')\n",
    "        ds = xr.merge([ds_a,ds_b])[['T','Z3']]\n",
    "        ds = ds.sel(plev=[200.,500.])\n",
    "        print(ds)\n",
    "   \n",
    "        \n",
    "        slope, intercept, r_value, p_value, std_err = myf.linregress(ds.year,ds.load(),dim='year')\n",
    "    \n",
    "        for var in ['T','Z3']:\n",
    "            slope[var].attrs['units'] = ds[var].attrs['units']+'/yr'\n",
    "            p_value[var] = 100.*p_value[var]\n",
    "            p_value[var].attrs['units'] = '%'\n",
    "            slope = slope.rename({var:var+'_trend'})\n",
    "            p_value = p_value.rename({var:var+'_p_value'})\n",
    "\n",
    "        seasds = xr.merge([slope, p_value])\n",
    "        listds.append(seasds)\n",
    "    ds = xr.concat(listds,dim='season')\n",
    "                   \n",
    "    \n",
    "    ds['names'] = name\n",
    "    ds = ds.set_coords('names')\n",
    "    ds.attrs['desc'] = 'processed by Lettie Roach, June 2021'\n",
    "    print(ds)\n",
    "    ds.to_netcdf(mydir+'processed/spatial_mean_trend/atm/'+str(name)+'.atm_Z3T_plev_climtrend.1979-2018.nc')\n",
    "    \n",
    "    return ds    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in ['anom_nudge_era_60_arclo']:\n",
    "    print(run)\n",
    "    get_timeseries(wrangle_nudge(run, myvariables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1,36,1):\n",
    "    ds = (wrangle_lens(e, myvariables))\n",
    "    get_timeseries(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab relevant stuff for ERA-Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_z = xr.open_dataset('/glade/work/lettier/ERAI/mon/remap_cesmgrid/ei.moda.an.pl.regn128sc.1979-2018_z_remapcesmagrid.nc')\n",
    "ds_t = xr.open_dataset('/glade/work/lettier/ERAI/mon/remap_cesmgrid/ei.moda.an.pl.regn128sc.1979-2018_t_remapcesmagrid.nc')\n",
    "ds = xr.merge([ds_z,ds_t])\n",
    "ds = ds.rename({'isobaricInhPa':'plev','z':'Z3','t':'T'})\n",
    "ds['Z3'] = ds.Z3/9.81\n",
    "ds = ds.sel(time=slice('1979','2018'))\n",
    "name = 'ERAI'\n",
    "ds.Z3.attrs = {}\n",
    "ds.Z3.attrs['units'] = 'm'\n",
    "\n",
    "ds = ds.sel(plev=[200.,500.])\n",
    "ds['time'] = mytime\n",
    "print(ds)\n",
    "\n",
    "listds = []\n",
    "for seas in ['DJF','MAM','JJA','SON']:\n",
    "\n",
    "    seasds = ds.where(ds['time.season'] == seas).groupby('time.year').mean(dim='time')\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = myf.linregress(seasds.year,seasds.load(),dim='year')\n",
    "\n",
    "    for var in seasds:\n",
    "        slope[var].attrs['units'] =ds[var].attrs['units']+'/yr'\n",
    "        p_value[var] = 100.*p_value[var]\n",
    "        p_value[var].attrs['units'] = '%'\n",
    "        slope = slope.rename({var:var+'_trend'})\n",
    "        p_value = p_value.rename({var:var+'_p_value'})\n",
    "\n",
    "    seasds = xr.merge([slope, p_value])\n",
    "    seasds['season'] = seas\n",
    "    seasds = seasds.set_coords('season')\n",
    "    listds.append(seasds)\n",
    "ds = xr.concat(listds,dim='season')\n",
    "\n",
    "\n",
    "ds['names'] = name\n",
    "ds = ds.set_coords('names')\n",
    "ds.attrs['desc'] = 'processed by Lettie Roach, June 2021'\n",
    "print(ds)\n",
    "ds.to_netcdf(mydir+'processed/spatial_mean_trend/atm/'+str(name)+'.atm_Z3T_plev_climtrend.1979-2018.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-myenv]",
   "language": "python",
   "name": "conda-env-anaconda3-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
